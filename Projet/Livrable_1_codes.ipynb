{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48560da6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T08:36:24.956539Z",
     "start_time": "2023-01-06T08:36:18.681698Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "940a7d54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T08:36:24.972507Z",
     "start_time": "2023-01-06T08:36:24.958597Z"
    }
   },
   "outputs": [],
   "source": [
    "project_path = r\"..\\Datasets_test_binary\\OneDrive_2022-09-22\\Dataset projet\"\n",
    "other_dir = project_path + r\"\\other\"\n",
    "photo_dir = project_path + r\"\\photo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ad948c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T08:36:35.264467Z",
     "start_time": "2023-01-06T08:36:24.974506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41405 files belonging to 2 classes.\n",
      "Using 33124 files for training.\n",
      "Using 8281 files for validation.\n",
      "\n",
      "The dataset is composed of these classes : ['Other', 'Photo']\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    project_path,\n",
    "    validation_split=0.2,\n",
    "    seed=10,\n",
    "    image_size = (384, 384),\n",
    "    batch_size=128,\n",
    "    subset = \"both\"\n",
    ")\n",
    "print(f\"\\nThe dataset is composed of these classes : {train_set.class_names}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acf8570",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# III. Mise en place des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4c5aaf",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Expliquer la mise en place d'un modèle : \n",
    "\n",
    "- Definition du modèle\n",
    "- Compilation du modèle (expliquer optimizer et function loss // pourquoi on a choisi ceux-là)\n",
    "- Fit du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761ef511",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## A. Modèles de base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def6419a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1. NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b01dcac",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1.1. Définition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d6214",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255, offset=0.0),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb0a19",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1.2. Compilation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1242607",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac429702",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1.3. Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abdc253",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "history = model.fit(train_set, validation_data=test_set, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c469fc66",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1.4. Résultats du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c92be29",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce96db2",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc4dc2d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2.1. Définition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24df3b5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255, offset=0.0),\n",
    "    tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48cc02f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2.2. Compilation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471f46f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf772b56",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2.3. Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae3c457",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "history = model.fit(train_set, validation_data=test_set, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dab086",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2.4. Résultats du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa4769",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4bdd2f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## B. Régularisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b50a0a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "La régularisation en intelligence artificielle est une technique utilisée pour empêcher ou réduire le surapprentissage d'un modèle de deep learning. La régularisation consiste à ajouter une contrainte au processus d'apprentissage du modèle afin de le forcer à rester simple et généralisable. En utilisant cette technique, on peut améliorer les performances d'un modèle sur de nouvelles données et le rendre plus capable de gérer des situations inattendues.\n",
    "\n",
    "Il existe plusieurs méthodes de régularisations comme par exemple :\n",
    "\n",
    "\n",
    "- le Dropout : cette méthode consiste à désactiver aléatoirement un pourcentage de neurones d'une couche pendant l'entraînement. Cela permet d'empêcher les neurones de dépendre trop les uns des autres et d'améliorer la généralisation de la modèle à de nouvelles données.\n",
    "\n",
    "\n",
    "- la Data Augmentation : cette méthode consiste à générer de nouvelles données à partir des données d'entraînement existantes en appliquant des transformations aléatoires telles que des rotations, des translations, des miroirs, des changements de luminosité, etc... dans le but d'augmenter la quantité de données disponibles pour l'entraînement d'un modèle.\n",
    "\n",
    "\n",
    "- la régularisation L1, L2, Elastic-Net : ces méthodes consistent à modifier la fonction de coût dans le but  de réduire la complexité du modèle en mettant à zéro certains poids (L1), en atténuant les valeurs des poids (L2), ou en combinant ces deux actions (Elastic-Net). \n",
    "\n",
    "\n",
    "- la Batch Normalization : cette méthode consiste à normaliser les activations d'une couche en utilisant les moyennes et les écarts-types des activations de chaque batch d'exemples d'entraînement. Cela a pour effet d'améliorer la convergence et la stabilité des réseaux de neurones.\n",
    "\n",
    "\n",
    "- l'Early Stopping : cette méthode consiste à arrêter l'entraînement d'un modèle avant que la performance ne commence à décliner sur l'ensemble de validation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b881a30a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1. Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e504cfa8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Ici, nous allons utiliser un dropout à 20%. Cela signifie que sur toutes les couches contraintes avec un dropout, 20% des neurones seront aléatoirement désactivés par itération."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4f32ac",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1.1. Définition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18241950",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1. / 255, offset=0.0),\n",
    "    tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ea528",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1.2. Compilation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d38229d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaf1ffa",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1.3. Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907b6c39",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "history = model.fit(train_set, validation_data=test_set, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14910b8b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1.4. Résultats du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a369c9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a8bb03",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2. Résultats des autres régularisations testées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dacb6e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-06T08:31:07.489360Z",
     "start_time": "2023-01-06T08:31:07.471213Z"
    },
    "hidden": true
   },
   "source": [
    "Tableau récapitulatif des résultats des autres régularisations testées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f817b0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "| Nom | Description | Précision d'entrainement| Précision de test | Nombre d'époque | Temps moyen par époque|\n",
    "| :-------: |:---------------:|:-----:|:---------:|:---------:|:---------:|\n",
    "|CNN (WS) + Dropout 20% + Padding|Modèle seul|0.93|0.93|10|2min|\n",
    "|CNN (WS) + Dropout 20% + Padding|Modele seul + L1L2 Regularization (Elastic-Net)|0.79|0.70|10|1min45|\n",
    "|CNN (WS) + Dropout 20% + Padding|Modèle seul + Batch Normalization|0.96|0.90|10|2min|\n",
    "|CNN (WS) + Dropout 20%|Modèle + Data Augmentation|0.89|0.87|10|8-10min|\n",
    "|CNN (WS) + Dropout 20%|Modèle seul|0.98|0.90|20|2min|\n",
    "|CNN (WS) + Dropout 20%|Modèle seul + rotation des images dans un même sens (taille)|0.95|0.89|10|2min|\n",
    "|CNN (WS) + Dropout 20%|Modèle seul + rotation des images dans un même sens + data augmentation|0.87|0.83|10|8min30|\n",
    "|CNN (WS) + Dropout 20%|Modèle seul + DataGenerator|0.87|0.84|10|3min15|\n",
    "|CNN (WS) + Dropout 20%|Modèle seul + DataGenerator + DataAugmentation|0.87|0.85|20|5min|\n",
    "|CNN (WS) + Dropout 50%|Modèle seul|0.88|0.90|20|2min|\n",
    "|CNN (WS) + Dropout 35%|Modèle seul|0.93|0.89|15|2min|\n",
    "|CNN (WS) + Dropout 50%|Modèle seul|0.91|0.87|10|2min|\n",
    "|CNN|Modèle + data augmentation|0.90|0.86|10|6min40|\n",
    "|CNN|Modèle seul|0.99|0.91|10|1min50|\n",
    "|CNN|Modèle seul + rotation des images dans un même sens (taille)|0.99|0.91|10|1min40|\n",
    "|CNN|Modèle seul + rotation des images dans un même sens + data augmentation|0.90|0.86|10|7-8min|\n",
    "|Pas de CNN (WS)|Modèle seul (Pas de CNN)|0.79|0.76|10|1min20|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c804b472",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## C. Architecture existantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517231f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Enfin, nous avons voulu utiliser des architechtures déjà existants, dans la litterature scientifique. Pour cela, nous avons d'abord choisi de reproduire une architecture existante. Pour cela, nous avons cherché des modèles performants et comprenant relativement peu de couches, afin de pouvoir l'executer sur nos machines.\n",
    "\n",
    "Ainsi, nous avons utilisé le modèle VGG11 qui est un bon compromis de nos contraintes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f03aa64",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 1. VGG11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d686e175",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Le modèle VGG11 a été développé par l'équipe de recherche Visual Geometry Group (VGG) de l'université de Oxford en 2014. Il a été présenté pour la première fois dans un article de recherche intitulé \"Very Deep Convolutional Networks for Large-Scale Image Recognition\". Depuis sa publication, le modèle VGG11 est devenu l'un des modèles de reconnaissance d'images les plus populaires et a été utilisé dans de nombreuses recherches et applications en vision par ordinateur. Il est souvent utilisé comme base pour le développement de nouvelles méthodes en reconnaissance d'images et reste l'un des modèles les plus performants dans de nombreuses tâches de vision par ordinateur.\n",
    "\n",
    "Ce réseau de neurones a été entraîné sur la base de données ImageNet. Il utilise une architecture de réseau convolutionnel profond avec 11 couches de convolution et 3 couches fully connected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c98aea4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "| Nom | Description | Précision d'entrainement| Précision de test | Nombre d'époque | Temps moyen par époque|\n",
    "| :-------: |:---------------:|:-----:|:---------:|:---------:|:---------:|\n",
    "|VGG-11 architecture|Modèle seul|0.95|0.91|20|3-4min|\n",
    "|VGG-11 architecture customisée|Modèle seul|0.92|0.91|10|1min30|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a97920",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 2. EfficientNetV2B0 en Transfert Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5edc40",
   "metadata": {
    "hidden": true
   },
   "source": [
    "EfficientNetV2B0 est un modèle de reconnaissance d'images pré-entraîné développé par Google et publié en 2021, qui utilise une architecture de réseau de neurones convolutionnel (CNN) optimisée pour être efficace en termes de consommation de ressources informatiques tout en conservant une haute performance. Il a été entraîné sur la base de données ImageNet et a été utilisé avec succès dans de nombreuses tâches de vision par ordinateur, telles que la détection d'objets, la classification d'images et la génération de descriptions de contenu d'image. Ce réseau de neurones a été entraîné sur la base de données ImageNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15c644",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Le transfert learning est une technique qui permet de réutiliser les connaissances acquises par un modèle pré-entraîné sur une tâche donnée pour entraîner un nouveau modèle sur une tâche différente. Cela peut être utile lorsqu'il y a peu de données disponibles pour entraîner un modèle sur la tâche spécifique, ou lorsqu'il est difficile de collecter ces données. Le transfert learning peut également aider à améliorer les performances d'un modèle sur une tâche spécifique en utilisant les connaissances acquises par un modèle pré-entraîné sur une tâche similaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3691dcd0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2.1. Définition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d06710",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B0\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "class OwnEfficientNetV2B0:  \n",
    "    @staticmethod\n",
    "    def build(input_shape, trainable=False, dropout=0.2):\n",
    "        inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "        baseModel = EfficientNetV2B0(weights=\"imagenet\", include_top=False, input_tensor=inputs)\n",
    "        baseModel.trainable = trainable\n",
    "\n",
    "        headModel = baseModel.output\n",
    "        headModel = layers.GlobalAveragePooling2D()(headModel)\n",
    "        headModel = layers.Dropout(dropout)(headModel)\n",
    "        outputs = layers.Dense(1, activation=\"sigmoid\")(headModel)\n",
    "        model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "        return model\n",
    "\n",
    "model = OwnEfficientNetV2B0().build(input_shape=(384, 384, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87951c24",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2.2. Compilation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a7e34",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe76086",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2.3. Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf9aff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "history = model.fit(train_set, validation_data=test_set, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7805ce4b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2.4. Résultats du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d2cfc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e8f0e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# IV. Résultats et conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e345b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "| Nom | Description | Précision d'entrainement| Précision de test | Nombre d'époque | Temps moyen par époque|\n",
    "| :-------: |:---------------:|:-----:|:---------:|:---------:|:---------:|\n",
    "|CNN (WS) + Dropout 20% + Padding|Modèle seul|0.93|0.93|10|2min|\n",
    "|CNN (WS) + Dropout 20% + Padding|Modele seul + L1L2 Regularization (Elastic-Net)|0.79|0.70|10|1min45|\n",
    "|CNN (WS) + Dropout 20% + Padding|Modèle seul + Batch Normalization|0.96|0.90|10|2min|\n",
    "|CNN (WS) + Dropout 20%|Modèle + Data Augmentation|0.89|0.87|10|8-10min|\n",
    "|CNN (WS) + Dropout 20%|Modèle seul|0.98|0.90|20|2min|\n",
    "|CNN (WS) + Dropout 20%|Modèle seul + rotation des images dans un même sens (taille)|0.95|0.89|10|2min|\n",
    "|CNN (WS) + Dropout 20%|Modèle seul + rotation des images dans un même sens + data augmentation|0.87|0.83|10|8min30|\n",
    "|CNN (WS) + Dropout 20%|Modèle seul + DataGenerator|0.87|0.84|10|3min15|\n",
    "|CNN (WS) + Dropout 20%|Modèle seul + DataGenerator + DataAugmentation|0.87|0.85|20|5min|\n",
    "|CNN (WS) + Dropout 50%|Modèle seul|0.88|0.90|20|2min|\n",
    "|CNN (WS) + Dropout 35%|Modèle seul|0.93|0.89|15|2min|\n",
    "|CNN (WS) + Dropout 50%|Modèle seul|0.91|0.87|10|2min|\n",
    "|VGG-11 architecture|Modèle seul|0.95|0.91|20|3-4min|\n",
    "|VGG-11 architecture customisée|Modèle seul|0.92|0.91|10|1min30|\n",
    "|CNN|Modèle + data augmentation|0.90|0.86|10|6min40|\n",
    "|CNN|Modèle seul|0.99|0.91|10|1min50|\n",
    "|CNN|Modèle seul + rotation des images dans un même sens (taille)|0.99|0.91|10|1min40|\n",
    "|CNN|Modèle seul + rotation des images dans un même sens + data augmentation|0.90|0.86|10|7-8min|\n",
    "|Pas de CNN (WS)|Modèle seul (Pas de CNN)|0.79|0.76|10|1min20|\n",
    "|EfficientNetV2B0|Modèle EfficientNetV2B0 (gelé) Modification des deux derniere couches : GlobalAveragePooling2D Dense avec 1 neurone en sigmoid|0.99|0.99|10|2min|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
